---
title: "HW 6"
output: html_document
date: "2023-02-21"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(NHANES)
library(dplyr)
```

```{r process_data}
set.seed(123)
df <- NHANES[c("Age", "Race1", "Education", "HHIncome", "Weight", "Height", "Pulse", "Diabetes", "BMI", "PhysActive", "Smoke100")]

df <- na.omit(df)
head(df)

train.indices<-createDataPartition(y=df$Age,p=0.7,list=FALSE)
train.data<-df[train.indices, ]
test.data<-df[-train.indices, ]

# check for balance in labels
nrow(df[df$Diabetes == "No",])
nrow(df[df$Diabetes == "Yes",])
```
Clearly the data is imbalanced because there are 5697 people without diabetes and only 659 people with diabetes. So, in the parameters for the following models, we will use down-sampling.

__CaRT__
```{r tree}
#Creating 10-fold cross-validation and using down-sampling because of imbalance in data
train.control<-trainControl(method="cv", number=10, sampling="down")

#Create sequence of cp parameters to try 
tree.grid<-expand.grid(cp=seq(0.001, 0.3, by=0.01))

#Train model
tree.model <-train(Diabetes~., data=df, method="rpart",trControl=train.control, tuneGrid=tree.grid)

tree.model$bestTune
```
For the tree model, the best tune after a 10-fold cross validation gave me the optimal cp=0.001. The accuracy of the model for this particular cp was 0.735. 

__Support Vector Classifier__
```{r SVC}
svm.grid <- expand.grid(C=seq(0.001,2, length=30))
svm.model<-train(Diabetes~ ., data=df, method="svmLinear", trControl=train.control, preProcess=c("center", "scale"), tuneGrid=svm.grid)

svm.model$bestTune
```
After performing a 10-fold cross validation for the SVM model, I found that the optimal C was 1.517. The accuracy for predicting the training set with this hyperparameter was 0.713.

__Logistic Regression__
```{r Logistic}
log.model <- train(
  Diabetes ~., data = train.data, method = "glm", family="binomial",
  trControl = train.control, preProc=c("center", "scale"),
 tuneLength=10
  )

```
For this model there were no hyperparameters to tune. The accuracy for this model was 0.7286.

__Final Model__

Because the accuracy appeared to be the highest in the regression tree model, I will use this as the final model.

```{r selected}
tree.pred <- tree.model %>% predict(test.data)

confusionMatrix(tree.pred, test.data$Diabetes, positive="Yes")
```

The accuracy for the testing set was 0.7811. The other metrics shown in the confusion matrix above are also quite good (sensitivity: 0.853 and specificity: 0.77339).

__Evaluation__

For the tree model, one analytical limitation is that it is quite sensitive to small changes in data. If there are outliers, then relying on this tree alone (and how it creates splits) may give us entirely wrong classifications. Regarding applications to public health, I also think that there is a limitation in how it can be used. The tree method allows us to assign importances to variables based on predictability, but this does not always translate to applicability. For example, age may be a great predictor of diabetes. However, there is not much we can do to change age, so even if the model tells us the importance of age, it is not really relevant from a public health perspective.
